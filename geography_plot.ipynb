{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = \"merged_support3_random_1k_seed_42\"\n",
    "target_feature_suffix = \"_matrix.npy\"\n",
    "save_data_path = \"./results\"\n",
    "\n",
    "select_methods = [\"rf\"]# [\"random\", \"xgb\", \"rf\", \"variance\", \"chi2\", \"f_classif\"] # Extra-trees # \"mutual_info_classif\"\n",
    "    \n",
    "n_select_list = [256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072] #5105448\n",
    "n_dim_reduce_list = [128, 256, 512, 1024, None]  ## list should always contain None to perform whole feature training after selection\n",
    "ML_models = [\"SVM\"] #[\"SVM\", \"XGB\", \"RF\", \"DT\", \"KNN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_path, sample_annotation_file = get_data_path(save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 11:02:42,178 - INFO - [progress] Read data done. X.shape: (3202, 1000), y.shape: (3202,)\n",
      "2024-06-24 11:02:42,181 - INFO - [progress] Dropped 1 samples from the dataset. X.shape: (3201, 1000), y.shape: (3201,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 11:02:42,185 - INFO -  - Data_split: train_set (n= 1920), val_set (n= 640), test_set (n= 641)\n"
     ]
    }
   ],
   "source": [
    "dataset = data_loader(os.path.join(feature_data_path, target_feature + target_feature_suffix), \n",
    "                        sample_annotation_file)\n",
    "(X, y_original, y), (train_indices, val_indices, test_indices), label_mapping = dataset.get_data()\n",
    "\n",
    "\n",
    "result_combined = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save feature selection result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8192\n",
    "save_file_name = os.path.join(feature_data_path, target_feature + f\"_xgb_{n}\" + target_feature_suffix)\n",
    "\n",
    "X = np.load(os.path.join(feature_data_path, target_feature + target_feature_suffix))\n",
    "feature_importance_use = np.load(f\"1048576_seed42_xgb_basic_feature_importance_mean.npy\")\n",
    "selected_indices = np.argsort(feature_importance_use)[-n:][::-1]\n",
    "X_selected = X[:, selected_indices]\n",
    "np.save(save_file_name, X_selected)\n",
    "\n",
    "print(f\"saved result to {save_file_name} with shape {X_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare geography plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation_df = pd.read_csv(sample_annotation_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_code_to_name = sample_annotation_df[[\"Population code\", \"Population name\"]].drop_duplicates().reset_index(drop= True)\n",
    "# cls_code_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = {\n",
    "    'FIN': (25.0, 60.0),  # Finnish\n",
    "    'GBR': (-0.1276, 51.5074),  # British,English\n",
    "    'CHS': (113.7633, 22.18),  # Southern Han Chinese\n",
    "    'PUR': (-66.1057, 18.4655),  # Puerto Rican\n",
    "    'CDX': (100.212, 22.0000),  # Dai Chinese\n",
    "    'CLM': (-74.0817, 4.7110),  # Colombian\n",
    "    'IBS': (-3.7492, 40.4637),  # Iberian,Spanish\n",
    "    'KHV': (105.8542, 21.0285),  # Kinh Vietnamese\n",
    "    'PEL': (-77.0428, -12.0464),  # Peruvian\n",
    "    'PJL': (74.3587, 31.5204),  # Punjabi\n",
    "    'ACB': (-61.2225, 10.6918),  # African Caribbean\n",
    "    'GWD': (-15.3101, 13.4432),  # Gambian Mandinka\n",
    "    'ESN': (6.6745, 6.7439),  # Esan\n",
    "    'BEB': (90.4125, 23.8103),  # Bengali\n",
    "    'MSL': (-11.7383, 7.9647),  # Mende\n",
    "    'ITU': (78.4867, 17.3850),  # Telugu\n",
    "    'STU': (80.2707, 13.0827),  # Tamil\n",
    "    'CEU': (2.3522, 48.8566),  # CEPH\n",
    "    'YRI': (3.9470, 7.3775),  # Yoruba\n",
    "    'CHB': (116.4074, 39.9042),  # Han Chinese\n",
    "    'JPT': (139.6917, 35.6895),  # Japanese\n",
    "    'LWK': (34.7519, 0.2827),  # Luhya\n",
    "    'MXL': (-99.1332, 19.4326),  # Mexican Ancestry\n",
    "    'ASW': (-118.2437, 34.0522),  # African Ancestry SW\n",
    "    'TSI': (11.2558, 43.7696),  # Toscani\n",
    "    'GIH': (72.5714, 23.0225)  # Gujarati\n",
    "}  # Population code -> (longitude, latitude)\n",
    "color_palette = [\"#2A363B\", \"#355C7D\", \"#99B898\", \"#E84A5F\", \"#FF847C\", \"#FECEAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "\n",
    "def draw_pie_charts_on_map(cities, labs, save_file_name = None, y_log_trans = False):\n",
    "    \"\"\"\n",
    "    주어진 도시 목록에 대해 고해상도 세계지도 위에 파이 차트를 그립니다.\n",
    "\n",
    "    Parameters:\n",
    "    cities (list of dicts): 도시 정보를 담고 있는 리스트. 각 항목은 다음 키를 가짐:\n",
    "        - name (str): 도시 이름\n",
    "        - lon (float): 경도\n",
    "        - lat (float): 위도\n",
    "        - value (float): 파이 차트에서 첫 번째 조각의 비율\n",
    "        - radius (float): 파이 차트의 크기\n",
    "    \"\"\"\n",
    "    start_angle = 0\n",
    "\n",
    "    # 평면 지도 생성\n",
    "    fig, ax = plt.subplots(figsize=(15, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax.set_global()\n",
    "\n",
    "    # High-resolution coastlines and borders\n",
    "    coastline = cfeature.NaturalEarthFeature('physical', 'coastline', '110m', edgecolor='black', facecolor='none', linewidth=0.5)\n",
    "    borders = cfeature.NaturalEarthFeature('cultural', 'admin_0_boundary_lines_land', '110m', edgecolor='black', facecolor='none', linewidth=0.2)\n",
    "    ax.add_feature(coastline)\n",
    "    ax.add_feature(borders)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgrey')\n",
    "    ax.add_feature(cfeature.OCEAN, color='white')\n",
    "\n",
    "    if y_log_trans:\n",
    "        radius_normalize = np.mean([np.log10(city[\"radius\"]) for city in cities]) / 4\n",
    "    else:\n",
    "        radius_normalize = np.mean([city[\"radius\"] for city in cities]) / 4\n",
    "\n",
    "    # 각 도시에 대해 파이 차트 그리기\n",
    "    for city in cities:\n",
    "        if y_log_trans:\n",
    "            r = np.log10(city['radius'])\n",
    "        else:\n",
    "            r = city['radius']\n",
    "\n",
    "        if \"th2\" in city:\n",
    "            sizes = [city['th1'], city['th2'], 1-city['th1']-city['th2']]  # Proportions for the pie chart\n",
    "            colors = [color_palette[1], color_palette[2], color_palette[3]]  # Colors for train, validation, and test\n",
    "        else:\n",
    "            sizes = [city['th1'], 1 - city['th1']]\n",
    "            colors = [color_palette[1], color_palette[3]]\n",
    "        for size, color in zip(sizes, colors):\n",
    "            angle = 360 * size\n",
    "            wedge = Wedge(center=(city['lon'], city['lat']), r= r/ radius_normalize,\n",
    "                          theta1=start_angle, theta2=start_angle + angle,\n",
    "                          edgecolor='white', linewidth = 0.5, facecolor=color, transform=ccrs.Geodetic())\n",
    "            ax.add_patch(wedge)\n",
    "            start_angle += angle\n",
    "        # ax.text(city['lon'], city['lat'], city['name'], fontsize=8, ha='center', transform=ccrs.Geodetic())\n",
    "\n",
    "    # Add legend\n",
    "    theta_legends = []\n",
    "    theta_legends.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_palette[1], markersize=10, label=labs[\"th1\"]))\n",
    "    if \"th2\" in city:\n",
    "        theta_legends.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_palette[2], markersize=10, label=labs[\"th2\"]))\n",
    "    theta_legends.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_palette[3], markersize=10, label=labs[\"th_other\"]))\n",
    "    plt.legend(handles=theta_legends, loc=(0.05,0.05))\n",
    "\n",
    "    # Add legend for circle sizes\n",
    "    max_radius = max(city['radius'] for city in cities)\n",
    "    min_radius = min(city['radius'] for city in cities)\n",
    "    if y_log_trans:\n",
    "        legend_sizes = np.logspace(np.log10(min_radius), np.log10(max_radius), num=3)\n",
    "\n",
    "    else:\n",
    "        legend_sizes = np.arange(100, max_radius + 50, 50)#np.linspace(min_radius, max_radius, num=3)\n",
    "\n",
    "    gap_between_edges = 3  # Fixed gap between the edges of the circles\n",
    "    current_y = -57 + (len(theta_legends) - 3) * 7\n",
    "\n",
    "    for i, r in enumerate(legend_sizes):\n",
    "        r_val = np.log10(r) if y_log_trans else r\n",
    "        #legend location calcuation\n",
    "        loc_x = -155.5\n",
    "        loc_y = current_y + r_val / radius_normalize\n",
    "        current_y += (r_val / radius_normalize) * 2 + gap_between_edges\n",
    "\n",
    "        \n",
    "\n",
    "        circ = Circle((loc_x, loc_y), radius=r_val / radius_normalize, edgecolor='black', facecolor='lightgrey', transform=ccrs.Geodetic())\n",
    "        ax.add_patch(circ)\n",
    "        plt.text(loc_x + 10, loc_y, f'{round(r)} {labs[\"radius\"]}', fontsize=10, ha='left', va='center', transform=ccrs.Geodetic())\n",
    "        \n",
    "\n",
    "            \n",
    "    if save_file_name is not None:\n",
    "        plt.savefig(save_file_name, dpi = 300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig1. Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val, y_test = y_original[train_indices], y_original[val_indices], y_original[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = pd.DataFrame(y_original, columns=[\"class_label\"]).value_counts().reset_index(name='Total_Count')\n",
    "train_counts = pd.DataFrame(y_train, columns=[\"class_label\"]).value_counts().reset_index(name='Train_Count')\n",
    "val_counts = pd.DataFrame(y_val, columns=[\"class_label\"]).value_counts().reset_index(name='Val_Count')\n",
    "test_counts = pd.DataFrame(y_test, columns=[\"class_label\"]).value_counts().reset_index(name='Test_Count')\n",
    "\n",
    "# Merge the counts into a single dataframe\n",
    "combined_counts = pd.merge(total_counts, train_counts, on='class_label', how='outer')\n",
    "combined_counts = pd.merge(combined_counts, val_counts, on='class_label', how='outer')\n",
    "combined_counts = pd.merge(combined_counts, test_counts, on='class_label', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>Train_Count</th>\n",
       "      <th>Val_Count</th>\n",
       "      <th>Test_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEU</td>\n",
       "      <td>179</td>\n",
       "      <td>107</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YRI</td>\n",
       "      <td>178</td>\n",
       "      <td>107</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GWD</td>\n",
       "      <td>178</td>\n",
       "      <td>107</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHS</td>\n",
       "      <td>163</td>\n",
       "      <td>98</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBS</td>\n",
       "      <td>156</td>\n",
       "      <td>94</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESN</td>\n",
       "      <td>149</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PJL</td>\n",
       "      <td>146</td>\n",
       "      <td>88</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUR</td>\n",
       "      <td>139</td>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CLM</td>\n",
       "      <td>132</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BEB</td>\n",
       "      <td>131</td>\n",
       "      <td>79</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KHV</td>\n",
       "      <td>122</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PEL</td>\n",
       "      <td>122</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACB</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>STU</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TSI</td>\n",
       "      <td>107</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ITU</td>\n",
       "      <td>107</td>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JPT</td>\n",
       "      <td>104</td>\n",
       "      <td>62</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GIH</td>\n",
       "      <td>103</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CHB</td>\n",
       "      <td>103</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LWK</td>\n",
       "      <td>99</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MSL</td>\n",
       "      <td>99</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIN</td>\n",
       "      <td>99</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MXL</td>\n",
       "      <td>97</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CDX</td>\n",
       "      <td>93</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBR</td>\n",
       "      <td>91</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ASW</td>\n",
       "      <td>74</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_label  Total_Count  Train_Count  Val_Count  Test_Count\n",
       "0          CEU          179          107         36          36\n",
       "1          YRI          178          107         35          36\n",
       "2          GWD          178          107         35          36\n",
       "3          CHS          163           98         32          33\n",
       "4          IBS          156           94         31          31\n",
       "5          ESN          149           89         30          30\n",
       "6          PJL          146           88         29          29\n",
       "7          PUR          139           83         28          28\n",
       "8          CLM          132           80         26          26\n",
       "9          BEB          131           79         26          26\n",
       "10         KHV          122           74         24          24\n",
       "11         PEL          122           73         25          24\n",
       "12         ACB          116           70         23          23\n",
       "13         STU          114           68         23          23\n",
       "14         TSI          107           65         21          21\n",
       "15         ITU          107           64         22          21\n",
       "16         JPT          104           62         21          21\n",
       "17         GIH          103           61         21          21\n",
       "18         CHB          103           61         21          21\n",
       "19         LWK           99           59         20          20\n",
       "20         MSL           99           59         20          20\n",
       "21         FIN           99           59         20          20\n",
       "22         MXL           97           58         20          19\n",
       "23         CDX           93           56         18          19\n",
       "24         GBR           91           55         18          18\n",
       "25         ASW           74           44         15          15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "for idx, row in combined_counts.iterrows():\n",
    "    code = row['class_label']\n",
    "    if code in locations:\n",
    "        lon, lat = locations[code]\n",
    "        city = {\n",
    "            'name': code,\n",
    "            'lon': lon,\n",
    "            'lat': lat,\n",
    "            'th1': row[\"Train_Count\"] / row[\"Total_Count\"],  # This is an arbitrary placeholder, adjust as necessary\n",
    "            'th2': row[\"Val_Count\"] / row[\"Total_Count\"],  # This is an arbitrary placeholder, adjust as necessary\n",
    "            'radius': row[\"Total_Count\"],#  # Normalize by the largest possible value for visualization scaling\n",
    "        }\n",
    "        cities.append(city)\n",
    "    else:\n",
    "        print(code)\n",
    "\n",
    "\n",
    "draw_pie_charts_on_map(cities, labs = {\"th1\": \"Train\", \"th2\" : \"Validation\", \"th_other\" : \"Test\", \"radius\" : \"samples\"}, save_file_name=\"results/data_description.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig4. Number of features required for classifying each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minimum_n_by_cls = pd.read_csv(\"results/minimum_n_by_cls.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_class = \"FIN\"\n",
    "standard_n = df_minimum_n_by_cls[df_minimum_n_by_cls[\"class_target\"] == standard_class][\"select_n\"].iloc[0]\n",
    "\n",
    "feature_importance_standard = np.load(f\"8192_seed42_xgb_cls_{standard_class}_basic_feature_importance_mean.npy\")\n",
    "selected_indices_standard = np.argsort(feature_importance_standard)[-standard_n:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlab_dict = {}\n",
    "\n",
    "for i, r in df_minimum_n_by_cls.iterrows():\n",
    "    current_class = r[\"class_target\"]\n",
    "    current_n = r[\"select_n\"]\n",
    "    if current_class == standard_class:\n",
    "        overlab_dict[current_class] = 1\n",
    "    feature_importance_current = np.load(f\"8192_seed42_xgb_cls_{current_class}_basic_feature_importance_mean.npy\")\n",
    "    selected_indices_current = np.argsort(feature_importance_current)[-current_n:][::-1]\n",
    "    intersection = np.intersect1d(selected_indices_standard, selected_indices_current)\n",
    "    overlab_dict[current_class] = len(intersection) / current_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cities data list from the dataframe and location dictionary\n",
    "cities = []\n",
    "for idx, row in df_minimum_n_by_cls.iterrows():\n",
    "    code = row['class_target']\n",
    "    if code in locations:\n",
    "        lon, lat = locations[code]\n",
    "        city = {\n",
    "            'name': code,\n",
    "            'lon': lon,\n",
    "            'lat': lat,\n",
    "            'th1': 1- overlab_dict[code],  # This is an arbitrary placeholder, adjust as necessary\n",
    "            'radius': row['select_n']  # Normalize by the largest possible value for visualization scaling\n",
    "        }\n",
    "        cities.append(city)\n",
    "    else:\n",
    "        print(code)\n",
    "\n",
    "\n",
    "draw_pie_charts_on_map(cities, y_log_trans = True, labs = {\"th1\": \"other SNPs\", \"th_other\": \"SNPs overlap\", \"radius\": \"SNPs\"}, save_file_name=\"results/SNP_overlap.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinhyun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

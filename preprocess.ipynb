{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import vcfpy\n",
    "\n",
    "from helpers import get_ip_address, has_write_permission, save_preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_locations = {\n",
    "    '223.195.111.48': '/project/datacamp/team11/data',\n",
    "    '147.47.44.229': '/home/jinhyun/data/1kGP',\n",
    "}\n",
    "\n",
    "chr_list = [str(x) for x in range(1,23)]\n",
    "gt_dict = {\"0|0\" :0, \"0|1\" : 1, \"1|0\" : 2, \"1|1\" : 3 } # genotype dict for converting string-> inteter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_locations.get(get_ip_address(), '/not_found')\n",
    "sample_annotation_file = os.path.join(data_path, \"igsr-1000 genomes 30x on grch38.tsv\")\n",
    "output_path = os.path.join(data_path, \"preprocessed\")\n",
    "\n",
    "assert os.path.exists(data_path), f\"Data path not exists: {data_path} OR IP setting is incorrect: {get_ip_address()}\"\n",
    "assert os.path.isfile(sample_annotation_file), f\"File not exists : {sample_annotation_file}\"\n",
    "assert has_write_permission(data_path), f\"You do not have write permission for {data_path}\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "assert has_write_permission(output_path), f\"You do not have write permission for {output_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vcf_line_count(filename):\n",
    "    cmd = f\"grep -v '^#' {filename} | wc -l\"\n",
    "    result = subprocess.run(cmd, shell=True, text=True, capture_output=True)\n",
    "    return int(result.stdout.strip())\n",
    "\n",
    "def preprocess_vcf(vcf_file_name, sample_annotation_file, output_file_prefix):\n",
    "    vcf_line_count = count_vcf_line_count(vcf_file_name)\n",
    "    print(f\"----- processing {vcf_file_name} file with {vcf_line_count} variants -----\")\n",
    "\n",
    "    reader = vcfpy.Reader.from_path(vcf_file_name)\n",
    "    sample_names_from_vcf = reader.header.samples.names\n",
    "\n",
    "    gt_mat_raw = np.empty((vcf_line_count, len(sample_names_from_vcf)), dtype=np.int8)\n",
    "    gt_mat_raw.fill(0)\n",
    "\n",
    "    variant_info_header = ['CHROM', 'POS', 'REF', 'ALT']\n",
    "    variant_info_df_raw = pd.DataFrame(index = range(vcf_line_count), columns = variant_info_header, dtype = str)\n",
    "\n",
    "    status_counter = {\n",
    "        \"total_variant\" : 0,\n",
    "        \"total_snps\" : 0,\n",
    "        \"total_meaningful_snps\" : 0\n",
    "    }\n",
    "\n",
    "    for record in tqdm(reader, total = vcf_line_count):\n",
    "        status_counter[\"total_variant\"] += 1\n",
    "        if not record.is_snv():\n",
    "            continue\n",
    "        status_counter[\"total_snps\"] += 1\n",
    "\n",
    "        gt_int = [gt_dict[call.data.get('GT')] if call.data.get('GT') in gt_dict else len(gt_dict) for call in record.calls]\n",
    "        if all(v == 0 for v in gt_int):\n",
    "            continue\n",
    "        status_counter[\"total_meaningful_snps\"] += 1\n",
    "\n",
    "        assert len(gt_int) == gt_mat_raw.shape[1]\n",
    "        gt_mat_raw[status_counter[\"total_meaningful_snps\"]-1, :] = gt_int\n",
    "\n",
    "        variant_info = [record.CHROM, str(record.POS), record.REF] + [alt.value for alt in record.ALT]\n",
    "        variant_info_df_raw.iloc[status_counter[\"total_meaningful_snps\"]-1] = variant_info\n",
    "        \n",
    "    reader.close()\n",
    "\n",
    "    assert(status_counter[\"total_variant\"] == vcf_line_count)\n",
    "    print(status_counter)\n",
    "\n",
    "    sample_annotation = pd.read_csv(sample_annotation_file, sep=\"\\t\")\n",
    "    sample_name_to_idx = {name : idx for idx, name in enumerate(sample_names_from_vcf)}\n",
    "    indices_for_sort_sample = [sample_name_to_idx[name] for name in sample_annotation[\"Sample name\"]]\n",
    "\n",
    "    gt_mat = gt_mat_raw[:status_counter[\"total_meaningful_snps\"], :].transpose()[indices_for_sort_sample,:]\n",
    "    variant_info_df = variant_info_df_raw.iloc[:status_counter[\"total_meaningful_snps\"]]\n",
    "\n",
    "    save_preprocessed_data(gt_mat, variant_info_df, output_file_prefix)\n",
    "    print(f\"sample annotations (#samples, ) : {sample_annotation.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read each vcf file and convert to matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- processing /home/jinhyun/data/1kGP/test.vcf file with 4889 variants -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4889/4889 [01:33<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_variant': 4889, 'total_snps': 4243, 'total_meaningful_snps': 4243}\n",
      "genotype matrix shape (#samples, #features) : (3202, 4243) -> saved to /home/jinhyun/data/1kGP/preprocessed/chrT_matrix.npy\n",
      "variant info dataframe (#features, ): (4243, 4) -> saved to /home/jinhyun/data/1kGP/preprocessed/chrT_variant.csv\n",
      "sample annotations (#samples, ) : (3202, 9)\n"
     ]
    }
   ],
   "source": [
    "## inject a test code\n",
    "#preprocess_vcf(\"/home/jinhyun/data/1kGP/temp.vcf\", \n",
    "#               os.path.join(data_path, \"temp_igsr.tsv\"), \n",
    "#               os.path.join(output_path, \"chr_test\"))\n",
    "    \n",
    "#preprocess_vcf(os.path.join(data_path, \"test.vcf\"), \n",
    "#               sample_annotation_file, \n",
    "#               os.path.join(output_path, \"chrT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chr in chr_list[::-1]:\n",
    "    vcf_file_name = os.path.join(data_path, f\"1kGP_high_coverage_Illumina.chr{chr}.filtered.SNV_INDEL_SV_phased_panel.vcf\")\n",
    "    if not os.path.exists(vcf_file_name):\n",
    "        logging.warning(f\"can not find vcf file for chromosome {chr}\")\n",
    "        continue\n",
    "\n",
    "    preprocess_vcf(vcf_file_name, \n",
    "        sample_annotation_file, \n",
    "        os.path.join(output_path, f\"chr{chr}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinhyun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

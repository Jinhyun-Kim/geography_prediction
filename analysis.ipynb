{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import get_ip_address, has_write_permission, measure_performance, save_numpy_array, export_feature_array, SNPDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_locations = {\n",
    "    '223.195.111.48': '/project/datacamp/team11/data',\n",
    "    '147.47.44.229': '/home/jinhyun/data/1kGP',\n",
    "}\n",
    "\n",
    "chr_list = [str(x) for x in range(1,23)]\n",
    "gt_dict = {\"0|0\" :0, \"0|1\" : 1, \"1|0\" : 2, \"1|1\" : 3 } # genotype dict for converting string-> inteter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = data_locations.get(get_ip_address(), '/not_found')\n",
    "sample_annotation_file = os.path.join(raw_data_path, \"igsr-1000 genomes 30x on grch38.tsv\")\n",
    "preprocess_path = os.path.join(raw_data_path, \"preprocessed\")\n",
    "\n",
    "assert os.path.exists(preprocess_path), f\"Data path not exists: {raw_data_path} OR IP setting is incorrect: {get_ip_address()}\"\n",
    "assert os.path.isfile(sample_annotation_file), f\"File not exists : {sample_annotation_file}\"\n",
    "assert has_write_permission(preprocess_path), f\"You do not have write permission for {preprocess_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read sample annotation info with shape : (3202, 9)\n"
     ]
    }
   ],
   "source": [
    "sample_annotation_df = pd.read_csv(sample_annotation_file, sep=\"\\t\")\n",
    "print(f\"Read sample annotation info with shape : {sample_annotation_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data_name = \"merged_support3_variance_0.1\" #\"merged_support3_variance_0.1\" #\"merged\" #merged_support3\n",
    "target_data_file_prefix = os.path.join(preprocess_path, target_data_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from files /home/jinhyun/data/1kGP/preprocessed/merged_support3_variance_0.1_matrix.npy and /home/jinhyun/data/1kGP/preprocessed/merged_support3_variance_0.1_variant.csv\n",
      "Read genotype array of shape (3202, 5105448) and variant info dataframe of shape (5105448, 4)\n",
      "\n",
      "genotype array shape (#samples, #features) : (3202, 5105448)\n",
      "sample annotations (#samples, ) : (3202, 9)\n",
      "variant info dataframe (#features, ): (5105448, 4)\n"
     ]
    }
   ],
   "source": [
    "snp_dataset = SNPDataSet.from_file(target_data_file_prefix, sample_annotation_df)\n",
    "\n",
    "print(f\"\\ngenotype array shape (#samples, #features) : {snp_dataset.genotype_array.shape}\")\n",
    "print(f\"sample annotations (#samples, ) : {snp_dataset.sample_annotation_df.shape}\")\n",
    "print(f\"variant info dataframe (#features, ): {snp_dataset.variant_info_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save one-hot encoding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3202, 5105448) (3202, 5105448, 2)\n"
     ]
    }
   ],
   "source": [
    "genotype_array_onehot = snp_dataset.create_onehot_genotype_array(inplace = False, batch_initialize = False)\n",
    "print(snp_dataset.genotype_array.shape, genotype_array_onehot.shape)\n",
    "save_numpy_array(genotype_array_onehot, os.path.join(preprocess_path, f\"{target_data_name}_matrix_onehot.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting sample count filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_sample_count = (snp_dataset.genotype_array != 0).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(supporting_sample_count / snp_dataset.genotype_array.shape[0], bins=100, kde=True)  # 'bins' controls the number of bins, 'kde' adds a Kernel Density Estimate plot\n",
    "\n",
    "#plt.xscale('log')\n",
    "#plt.xlim(xmin, xmax)\n",
    "\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Population Allele Frequency')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supporting_count_filter = supporting_sample_count >= 3\n",
    "print(f\"This filter will retain {supporting_count_filter.sum()} /\", snp_dataset.genotype_array.shape[1], \"variants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.filter_variant(supporting_count_filter, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.save_data(os.path.join(preprocess_path, \"merged_support3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Based on Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First creation\n",
    "#snp_dataset.create_onehot_genotype_array(inplace = True, batch_initialize = True)\n",
    "#save_numpy_array(snp_dataset.genotype_array_onehot, os.path.join(preprocess_path, \"merged_support3_matrix_onehot.npy\"))\n",
    "\n",
    "## Loading from file\n",
    "snp_dataset.load_onehot_genotype_array(target_data_file_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance_filter(genotype_array_onehot, threshold = 0, batch_process = False):\n",
    "    # from sklearn.feature_selection import VarianceThreshold\n",
    "    # selector = VarianceThreshold(threshold = threshold)\n",
    "    # genotype_array_filtered = selector.fit_transform(genotype_array)\n",
    "    # mask = selector.get_support()\n",
    "    # print(f\"This filter will return {genotype_array_filtered.shape} /\", genotype_array.shape[1], f\"variants (\")\n",
    "    # print(f\"This filter will retain {mask.sum()} /\", genotype_array.shape[1], f\"variants (\", mask.sum()/genotype_array.shape[1] * 100,\"%)\")\n",
    "\n",
    "    if batch_process:\n",
    "        batch_size=100000\n",
    "        n_samples, n_snps, feature_dim = genotype_array_onehot.shape\n",
    "        variances = np.zeros((n_snps, feature_dim))\n",
    "    \n",
    "        for start in tqdm(range(0, n_snps, batch_size)):\n",
    "            end = min(start + batch_size, n_snps)\n",
    "            batch_var = np.var(genotype_array_onehot[:, start:end, :], axis=0)\n",
    "            variances[start:end, :] = batch_var\n",
    "    else:\n",
    "        variances = np.var(genotype_array_onehot, axis=0)\n",
    "\n",
    "    mask = (variances > threshold).any(axis=1)\n",
    "    print(f\"Variance filter (threshold = {threshold}) will retain {mask.sum()} /\", genotype_array_onehot.shape[1], f\"variants (\", mask.sum()/genotype_array_onehot.shape[1] * 100,\"%)\")\n",
    "\n",
    "    # sns.histplot(variances.reshape(-1), bins=100, kde=True)  # 'bins' controls the number of bins, 'kde' adds a Kernel Density Estimate plot\n",
    "    # plt.title('Histogram of Data')\n",
    "    # plt.xlabel('Variances')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.show()\n",
    "\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_filter = get_variance_filter(snp_dataset.genotype_array_onehot, threshold=0.1, batch_process = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.filter_variant(variance_filter, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.save_data(os.path.join(preprocess_path, \"merged_support3_variance_0.2499999\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "zero_ratio = (snp_dataset.genotype_array == 0).sum(axis=0) / snp_dataset.genotype_array.shape[0]\n",
    "\n",
    "zero_filter = zero_ratio <= threshold\n",
    "print(f\"This filter will retain {zero_filter.sum()} /\", snp_dataset.genotype_array.shape[1], \"variants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.filter_variant(zero_filter, inplace = True)\n",
    "snp_dataset.save_data(os.path.join(preprocess_path, \"merged_zerofilter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_random_selection = 10000\n",
    "\n",
    "num_snps = snp_dataset.genotype_array.shape[1]\n",
    "random_selection_filter = np.zeros(num_snps, dtype=bool)\n",
    "np.random.seed(1004)\n",
    "selected_indices = np.random.choice(num_snps, n_random_selection, replace=False)\n",
    "random_selection_filter[selected_indices] = True\n",
    "print(f\"This filter will retain {random_selection_filter.sum()} /\", snp_dataset.genotype_array.shape[1], \"variants\")\n",
    "\n",
    "#snp_dataset_filtered = snp_dataset.filter_variant(random_selection_filter, inplace = False)\n",
    "snp_dataset.filter_variant(random_selection_filter, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.save_data(os.path.join(preprocess_path, \"merged_support3_variance_0.24995_random_10k\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression, r_regression, mutual_info_classif\n",
    "@measure_performance\n",
    "def uni_feature_selection(X, y, score_func, n = 10000):\n",
    "    print(f\"input array shape : {X.shape}, {y.shape}. n = {n}\")\n",
    "    X_selected = SelectKBest(score_func, k = n).fit_transform(X, y)\n",
    "    print(f\"output array shape : {X_selected.shape}\")\n",
    "\n",
    "    return(X_selected)\n",
    "\n",
    "n_select = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected, perf_metrics = uni_feature_selection(X = snp_dataset.genotype_array,\n",
    "                            y = sample_annotation_df[\"Population code\"],\n",
    "                            score_func = chi2,\n",
    "                            n = n_select)\n",
    "save_numpy_array(X_selected, numpy_save_file_name= os.path.join(preprocess_path,f\"{target_data_name}_chi2_10k_matrix.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = uni_feature_selection(X = snp_dataset.genotype_array,\n",
    "                            y = sample_annotation_df[\"Population code\"],\n",
    "                            score_func = f_classif,\n",
    "                            n = n_select)\n",
    "save_numpy_array(X_selected, numpy_save_file_name= os.path.join(preprocess_path,f\"{target_data_name}_f_classif_10k_matrix.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = uni_feature_selection(X = snp_dataset.genotype_array,\n",
    "                            y = sample_annotation_df[\"Population code\"],\n",
    "                            score_func = mutual_info_classif,\n",
    "                            n = n_select)\n",
    "save_numpy_array(X_selected, numpy_save_file_name= os.path.join(preprocess_path,f\"{target_data_name}_mutual_info_classif_10k_matrix.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurssive feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "@measure_performance\n",
    "def recursive_feature_selection(X, y, n = 10000):\n",
    "    print(f\"input array shape : {X.shape}, {y.shape}. n = {n}\")\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    sfs = SequentialFeatureSelector(knn, n_features_to_select = n)\n",
    "    sfs.fit(X, y)\n",
    "\n",
    "    #sfs.get_support()\n",
    "    X_selected = sfs.transform(X)\n",
    "    print(f\"output array shape : {X_selected.shape}\")\n",
    "\n",
    "    return X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_select = 100\n",
    "X_selected = recursive_feature_selection(X = snp_dataset.genotype_array,\n",
    "                                         y = sample_annotation_df[\"Population code\"],\n",
    "                                         n = n_select)\n",
    "\n",
    "#save_numpy_array(X_selected, numpy_save_file_name= os.path.join(preprocess_path,f\"{target_data_name}_chi2_10k_matrix.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_annotation_df[\"Superpopulation code\"].value_counts()\n",
    "sample_annotation_df[\"Population code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_dataset.create_onehot_genotype_array(inplace = True, batch_initialize = False)\n",
    "export_feature_array(snp_dataset.genotype_array_onehot, os.path.join(preprocess_path, \"merged_random_10k_onehot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def obtain_annovar_annotation(snp_dataset, save_path, annovar_path = \"/home/jinhyun/tools/annovar\"):\n",
    "    avinput_file_name = os.path.join(save_path, \"temp.avinput\")\n",
    "    annotate_file_prefix = os.path.join(save_path, \"temp\")\n",
    "    annotate_file_name = f\"{annotate_file_prefix}.hg38_multianno.txt\"\n",
    "\n",
    "    avinput_df = snp_dataset.variant_info_df.copy(deep= True).rename(columns = {\"POS\" : \"START\"})\n",
    "    avinput_df[\"END\"] = avinput_df[\"START\"]\n",
    "    avinput_df[['CHROM', 'START', 'END', 'REF', 'ALT']].to_csv(avinput_file_name, sep='\\t', index=False, header=False)\n",
    "\n",
    "    \n",
    "    cmd_run_annovar = f\"{annovar_path}/table_annovar.pl {avinput_file_name} {annovar_path}/humandb -buildver hg38 -out {annotate_file_prefix} -remove -protocol refGene,clinvar_20221231,avsnp150,intervar_20180118,gnomad40_genome,esp6500siv2_all,exac03,dbnsfp42c -operation g,f,f,f,f,f,f,f -nastring . \" #1000g2015aug\n",
    "    print(\"Performing annovar...\")\n",
    "    # print(cmd_run_annovar)\n",
    "    ret = subprocess.run(cmd_run_annovar, shell=True, text=True, capture_output=True)\n",
    "    os.remove(avinput_file_name)\n",
    "\n",
    "    try:\n",
    "        annotated_df = pd.read_csv(annotate_file_name, sep = \"\\t\", header = 0, na_values=[\".\"], dtype = str)\n",
    "        os.remove(annotate_file_name)\n",
    "        print(f\"read ANNOVAR annotated result of shape {annotated_df.shape}\")\n",
    "    except:\n",
    "        print(\"[warn] could not read annovar result.\")\n",
    "        return None\n",
    "    \n",
    "    return(annotated_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_annot_annovar_df = obtain_annovar_annotation(snp_dataset, save_path=preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_annot_annovar_df[\"Func.refGene\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def convert_annotation_into_numpy(df, column_names):\n",
    "    array_list = []\n",
    "    for c_name in column_names:\n",
    "        encoder = LabelEncoder()\n",
    "        annotation_coded_array = encoder.fit_transform(df[c_name]) #variant_annot_annovar_df['Func.refGene_encoded']\n",
    "        annotation_coded_array_reshaped = annotation_coded_array.reshape(1, -1, 1)\n",
    "        array_list.append(annotation_coded_array_reshaped)\n",
    "        # print(df[c_name].value_counts(), np.unique(annotation_coded_array, return_counts=True))\n",
    "\n",
    "\n",
    "    merged_array = np.concatenate(array_list, axis = 2)\n",
    "    print(f\"Encoded gene annotation {column_names} and created numpy array of shape {merged_array.shape}\")\n",
    "    return(merged_array)\n",
    "def merge_genotype_array_with_annotation(gt_array, annot_array):\n",
    "    assert gt_array.shape[1] == annot_array.shape[1]\n",
    "    annot_array_repeated = np.repeat(annot_array, gt_array.shape[0], axis=0)\n",
    "\n",
    "    merged_array = np.concatenate([np.expand_dims(gt_array, axis = 2), annot_array_repeated], axis=2)\n",
    "    print(f\"Obtained merged array of shape {merged_array.shape} from genotype array of shape {gt_array.shape} and annotation array of {annot_array_repeated.shape}\")\n",
    "    return(merged_array)\n",
    "gene_annotation_array = convert_annotation_into_numpy(variant_annot_annovar_df, [\"Func.refGene\"]) #\"Ref\", \"Alt\", \n",
    "\n",
    "save_genotype_array(merge_genotype_array_with_annotation(snp_dataset.genotype_array, gene_annotation_array), os.path.join(preprocess_path, \"merged_random_10k_annotated\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimension reduction by PCA and t_SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype_array_onehot = snp_dataset.create_onehot_genotype_array(inplace = False, batch_initialize = False)\n",
    "print(snp_dataset.genotype_array.shape, genotype_array_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del snp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data and label for PCA and t-SNE\n",
    "data_array = genotype_array_onehot.reshape(genotype_array_onehot.shape[0], -1) #flatten last feature dims\n",
    "labels = np.array(snp_dataset.sample_annotation_df[\"Population name\"]) #Population name #Superpopulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for label in np.unique(labels):\n",
    "    indices = np.where(labels == label)\n",
    "    plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=label, alpha=0.5)\n",
    "plt.title(f'PCA of {snp_dataset.genotype_array.shape[1]} SNPs')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(loc=1, prop={'size': 5})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "tsne_result = tsne.fit_transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "labels_unique = np.unique(labels)\n",
    "colors = cm.viridis(np.linspace(0, 1, len(labels_unique)))  # Using viridis colormap\n",
    "\n",
    "for label, color in zip(labels_unique, colors):\n",
    "    indices = np.where(labels == label)\n",
    "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=label, alpha=0.3,\n",
    "                #color=color,\n",
    "                ) \n",
    "\n",
    "plt.title(f't-SNE of {snp_dataset.genotype_array.shape[1]} SNPs')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.legend(loc=1, prop={'size': 5})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1,2,3], [2,3,0,1]])\n",
    "v = pd.DataFrame([[\"a\", \"b\"], [\"c\", \"d\"], [\"e\", \"f\"], [\"g\", \"h\"]])\n",
    "data = SNPDataSet(a,v,sample_annotation_df[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = data.create_onehot_genotype_array(batch_initialize=False)\n",
    "t2 = data.create_onehot_genotype_array(batch_initialize=True)\n",
    "print((t1 == t2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = 1,0\n",
    "print(data.genotype_array[i,j], t1[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jinhyun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
